{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief Project : OSINT Web Scraping (level imiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img src=https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcShSNuITX-DU4GNs8NUjxVe06sR6hQs7qe7O_SITovAbe8AUcO7 /></p>  \n",
    "\n",
    "\n",
    "- **[Exemple](<https://hackernoon.com/scraping-amazon-product-information-with-python-and-beautifulsoup-yn4s3tgr>) de scraping du site Amazon**\n",
    "- **[webscraper](https://chrome.google.com/webstore/detail/web-scraper/jnhgnonknehpejjnehehllkliplmbmhn/related?hl=fr) est une [extenstion Chrome](https://chrome.google.com/webstore/search/scraping?hl=fr&_category=ext/7-productivity) pour _scraper et exporter la data en csv_, [Tuto](http://webscraper.io/tutorials) et [certains sites statiques](<https://www.webscraper.io/test-sites>) (_pour s'entraîner dessus_)**<br>\n",
    "- **[SelectorsHub](https://selectorshub.com/) ([Lien d'installation](https://chrome.google.com/webstore/detail/selectorshub-xpath-plugin/ndgimibanhlabgdgjcpbbndiehljcpfh?hl=fr)) pour réccupérer facilement le XPath d'un élément (...).**  \n",
    "- **Réccupérer facilement les `Headers, User-Agent` à l'aide de <https://curlconverter.com/#> et passer inaperçue avec le pkg python [shadow-useragent](https://lobstr.io/index.php/2019/08/28/comment-changer-user-agent-et-rester-incognito-python-requests/) ou encore en suivant cet article [medium](https://medium.com/swlh/scraping-hotel-listings-from-booking-com-with-python-and-beautifulsoup-50fb9c435d9e)**\n",
    "- **Rq :** _Quand vous scrappez, essayez de simuler le comportement d'un humain (délai random, ...), un scrap trop intensif  => ip bloquée !_ Par ex : `time.sleep(round(random.uniform(3, 5), 1))`\n",
    "\n",
    "***     \n",
    "**`HTML`** | **`HTML`**\n",
    "--- | --- \n",
    "<p align=\"center\"><img src=https://user.oc-static.com/files/340001_341000/340563.png /> | <img src=http://www.cleantutorials.com/wp-content/uploads/2015/11/html-tag.png /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# libraries\n",
    "- **La documentation de [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#quick-start)**  \n",
    "- **La documentation de [requests](https://docs.python-requests.org/en/latest) : pkg moderne et simple d’utilisation comparativement à [urllib](https://docs.python.org/fr/3/library/urllib.html)) ? Pour vous aider [[video](https://www.youtube.com/watch?v=tb8gHvYlCFs)]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2023-04-18T09:35:37.184578Z",
     "end_time": "2023-04-18T09:35:41.760484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: Could not find a version that satisfies the requirement pprint (from versions: none)\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[31mERROR: No matching distribution found for pprint\u001B[0m\u001B[31m\r\n",
      "\u001B[0mRequirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (2.28.1)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (1.26.11)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (2022.9.24)\r\n",
      "Requirement already satisfied: bs4 in /opt/anaconda3/lib/python3.9/site-packages (0.0.1)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.9/site-packages (from bs4) (4.11.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->bs4) (2.3.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pprint\n",
    "!pip install requests\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T09:35:41.764157Z",
     "end_time": "2023-04-18T09:35:43.466550Z"
    }
   },
   "outputs": [],
   "source": [
    "# les imports\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "# Ex : Scraper une page basique \n",
    "- **Après avoir identifié la structure de la page suivante : <http://pythonscraping.com/pages/page1.html>**    \n",
    "    - Sur mon navigateur web (Chrome, mozilla ...) j'utilise la fonction `inspecter` (`click droit` / `inspecter`) et je fais glisser ma souris vers les zones de la page qui m'intéresse. Je verrai en même temps le script `html` se déplacer. C'est comme ça que je fais pour reperer les balises qui m'interessent\n",
    "    - Scraper ses différents éléments ? Indice : *`head`, `title`, `body`, `h1`, `div`* ; Exemple : `h1` => \"*An Interesting Title*, ...\" ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "## tp essai\n",
    "url = \"https://pythonprogramming.net/parsememcparseface/\"\n",
    "html = requests.get(url)\n",
    "##print(html.status_code)\n",
    "soup = BeautifulSoup(html.content,'lxml')\n",
    "#print(site)\n",
    "\n",
    "#print(htmlContent)\n",
    "#soup.find('div', {'class': 'box cb-mostpop'})\n",
    "introduction = soup.find('p', class_='introduction')\n",
    "# class=\"page-footer\"\n",
    "table = soup.findAll('ul')\n",
    "\n",
    "image = soup.find('img', class_=\"responsive-img\")\n",
    "imageUrl = image['src']\n",
    "#print(imageUrl)\n",
    "\n",
    "imageData = requests.get(imageUrl).content\n",
    "with open('Monimage.jpg', 'wb') as handler:\n",
    "   handler.write(imageData)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T09:35:43.468999Z",
     "end_time": "2023-04-18T09:35:44.257851Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T09:35:44.258051Z",
     "end_time": "2023-04-18T09:35:44.268922Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ZONE DE TP DU COURS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/f1/jvzhrs0d00gg34f_f6mn0l7h0000gn/T/ipykernel_8461/1857147134.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m  \u001B[0;31m#  print(text.get_text())\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;31m# just la limite qui change en fonction du nombre d'elements à renvoyer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0mgreenText\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msoup2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfindA\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'span'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'green'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlimit\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mtext\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mgreenText\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_text\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "#Ex : Scraper une page complexe: le but est de recuperer les tu text dont la classe est red ou grenn\n",
    "url2 = \"http://www.pythonscraping.com/pages/warandpeace.html\"\n",
    "html2 = requests.get(url2)\n",
    "#print(html2)\n",
    "soup2 = BeautifulSoup(html2.content, 'lxml')\n",
    "# text en rouge\n",
    "#redText = soup2.findAll('span', class_ = 'red',limit=3)\n",
    "#for text in redText:\n",
    " #  print(text.get_text())\n",
    "# just la limite qui change en fonction du nombre d'elements à renvoyer\n",
    "greenText = soup2.findA('span', class_ = 'green', limit= 2)\n",
    "for text in greenText:\n",
    "    print(text.get_text())\n",
    "greenText\n",
    "\n",
    "# le mot prince\n",
    "\n",
    "prince = soup2.find(name='')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T15:06:25.408432Z",
     "end_time": "2023-04-17T15:06:25.972050Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#  scraping new york time\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    ###  Réponse en passant par la lib requests\n",
    "# L'url du site à scrapper\n",
    "# url = \"http://pythonscraping.com/pages/page1.html\"\n",
    "# J'emet ma requet HTTP avec un\"GET\" au serveur\n",
    "# html = requests.get(url) \n",
    "# J'affiche l'url requété ainsi que le retour du serveur\n",
    "# print(url, html.status_code)\n",
    "# print(type(html))\n",
    "# print(html.text)\n",
    "# print(html.content)\n",
    "# Je demande à beautifulSoup de conserver dans une variable soup la page web scrappée\n",
    "soup = BeautifulSoup(html.content, \"lxml\")\n",
    "print(soup)\n",
    "print(\"________________________________________\")\n",
    "print(soup.prettify())\n",
    "print(\"________________________________________\")\n",
    "print(soup.h1.text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "- ## R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Réponse en passant par la lib urllib\n",
    "\n",
    "# from urllib.request import urlopen\n",
    "# url = \"http://pythonscraping.com/pages/page1.html\"\n",
    "html = urlopen(url)\n",
    "# print(type(html))     # class 'http.client.HTTPResponse'                  \n",
    "# print(html.read()) #  Ts le contenu du fichier est stocké ds 1 \"chaîne de charactère\" format binaire\n",
    "# print(type(html.read()))\n",
    "\n",
    "\n",
    "# bsObj = BeautifulSoup(html.read(), 'lxml')\n",
    "# print(type(bsObj))\n",
    "# print(bsObj)\n",
    "\n",
    "# print(bsObj.html.body.h1)\n",
    "# print(bsObj.body.h1)\n",
    "# print(bsObj.html.h1)\n",
    "print(bsObj.h1)\n",
    "# Les 4 derniers print() sont équivalents. \n",
    "#Je ne vs précise pas laquelle utiliser MAIS soyez cohérent tt au long de votre code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.html)\n",
    "# print(soup.head)\n",
    "# print(soup.head.title)\n",
    "# print(soup.title.text.strip())\n",
    "# print(soup.body)\n",
    "# print(soup.div.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://sophieetstephanie.files.wordpress.com/2013/11/tableau-codes-html.gif\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "# Ex : Scraper la page [parsememcparseface](https://pythonprogramming.net/parsememcparseface/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# html = requests.get('https://pythonprogramming.net/parsememcparseface/').content\n",
    "# print(html)\n",
    "# soup = BeautifulSoup(html, 'lxml')\n",
    "# print(type(soup), soup)\n",
    "## title of the page\n",
    "# print(soup.title)\n",
    "## get attributes:\n",
    "# print(soup.title.name, type(soup.title.name))\n",
    "## get values:\n",
    "# print(soup.title.string.strip())\n",
    "# print(soup.title.text, type(soup.title.text))\n",
    "# # Imprimer le 1er parag\n",
    "# print(soup.p)\n",
    "# # Imprimer tt les parag\n",
    "# pprint(soup.find_all('p'))\n",
    "# len(soup.find_all('p'))\n",
    "\n",
    "## beginning navigation:\n",
    "# print(soup.title.parent.name)\n",
    "# print(soup.title.parent)\n",
    "# print(soup.findAll()) \n",
    "\n",
    "# Q : Scraper la page dans l'objectif de réccupérer les diff éléments : tableau, image, etc.\n",
    "# R : \n",
    "# https://medium.com/geekculture/web-scraping-tables-in-python-using-beautiful-soup-8bbc31c5803e\n",
    "# Le tableau\n",
    "# table = soup.find(\"table\")\n",
    "# table\n",
    "# table_tr=table.find_all('tr')\n",
    "# table_tr\n",
    "# table_tr[0].find_all('th')\n",
    "# print(table_tr[0].find_all('th')[0].text)\n",
    "# print(table_tr[0].find_all('th')[1].text)\n",
    "# print(table_tr[0].find_all('th')[2].text)\n",
    "# table_tr[1]\n",
    "\n",
    "#nombre de ligne\n",
    "# row = table.find_all('tr')\n",
    "# row\n",
    "# row_length = len(row)\n",
    "# row_length\n",
    "\n",
    "# temp = [] #init\n",
    "# titre = []\n",
    "# nom = []\n",
    "# point = []\n",
    "# kittens = []\n",
    "\n",
    "## recupperer le titre du tableau\n",
    "# nom = row[0].find_all('th')[0].text\n",
    "# nom\n",
    "# point = row[0].find_all('th')[1].text\n",
    "# point\n",
    "# kittens = row[0].find_all('th')[2].text \n",
    "# kittens\n",
    "# titre.append((nom,point,kittens))  \n",
    "# titre\n",
    "\n",
    "## recuperer le contenu du tableau\n",
    "\n",
    "# for i in range(1, row_length):\n",
    "#         nom = row[i].find_all('td')[0].text\n",
    "#         point = row[i].find_all('td')[1].text\n",
    "#         kittens = row[i].find_all('td')[2].text \n",
    "#         temp.append([nom,point,kittens])         \n",
    "# temp\n",
    "\n",
    "## on verifie les lignes\n",
    "# len(temp)\n",
    "# df = pd.DataFrame(temp)\n",
    "# df\n",
    "\n",
    "# Réccupération des images\n",
    "for tag in soup.find_all(\"img\", class_=\"responsive-img\"):\n",
    "#     print(tag)\n",
    "    try:\n",
    "        src = tag.get(\"src\")\n",
    "        alt = tag.get(\"alt\")\n",
    "        print(src)\n",
    "        print(alt)\n",
    "    except Exception as e:\n",
    "        alt = None\n",
    "        print(alt)\n",
    "\n",
    "\n",
    "# tag = soup.find(\"img\", attrs={\"class\":\"responsive-img\"})\n",
    "# print(tag.get(\"alt\"))\n",
    "# print(tag.get(\"src\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "# Ex : Scraper une page complexe\n",
    "url2 = <http://www.pythonscraping.com/pages/warandpeace.html>  \n",
    "- **Après avoir identifié la structure de la page url2 (head, title, body, h1, h2, div, span),**\n",
    "    - Récupérer ts les mots en vert (ensuite en rouge) ? Le 1er, Les 5 premiers ? Indice => 1è mot en vert : Anna\n",
    "    - Récupérer ts les mots qui sont soit en rouge soit en vert ? Le 1er, Les 5 premiers ?\n",
    "    - Récupérer ts les mots qui correspondent à \"the prince\" en miniscule et coloré en vert ?\n",
    "        \n",
    "        \n",
    "## Réponse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# url = \"http://www.pythonscraping.com/pages/warandpeace.html\"\n",
    "# html = requests.get(url)\n",
    "# bsObj = BeautifulSoup(html.content, \"lxml\")\n",
    "# list_header = bsObj.find_all({\"h1\", \"h2\"})\n",
    "# isinstance(soup.find_all('a'), list)\n",
    "# print(f'*** list_header : {list_header}\\n')\n",
    "\n",
    "# for item in list_header : \n",
    "#     print(f'item : {item.get_text()}') \n",
    "\n",
    "# Q : Cmnt ça marche .get_text() ? \n",
    "# R : .get_text() strips all tags from the document and returns a string containing the text only. \n",
    "\n",
    "\n",
    "# list_div = bsObj.find_all(\"div\")\n",
    "# pprint(list_div)\n",
    "\n",
    "# list_span = bsObj.find_all(\"span\", limit = 5)\n",
    "# print(f'*** list_span : {list_span}')\n",
    "# print(len(list_span)) # 5\n",
    "\n",
    "# list_vert = bsObj.find_all({\"span\"}, {\"class\":\"green\"})\n",
    "# Rq : bsObj.find_all(tagName, tagAttributes) \n",
    "# print(f'*** list_vert : {list_vert}\\n')\n",
    "\n",
    "# for name in list_vert :\n",
    "#    print(name.get_text())\n",
    "\n",
    "# list_vert = [name.get_text() for name in list_vert]\n",
    "# list_vert\n",
    "# print(f'*** list_vert : {list_vert}\\n')\n",
    "\n",
    "\n",
    "# name_first = bsObj.find(\"span\", {\"class\":\"green\"})\n",
    "# print(f'*** name_first : {name_first.get_text()}\\n')\n",
    "\n",
    "list_prince = bsObj.find_all(\"span\", {\"class\":\"green\"}, text=\"the prince\")\n",
    "# Rq : findAll(tag, attributes, text, limit)\n",
    "# print(len(list_prince))\n",
    "# print(list_prince)\n",
    "prince = [prince.get_text() for prince in list_prince]\n",
    "prince"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "# Ex : Découvrir les autres fonctionnalités de bs4\n",
    "Q : télécharger cette [page](https://1drv.ms/u/s!AmJGbSlW18YGsdIav_vw3pordVoetQ?e=bIck4S) html ? Ce qui correspond à : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html= \"\"\"\n",
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"block1\">\n",
    "            <h1> Les meilleurs citations </h1>\n",
    "\n",
    "                <h2> Horace Mann </h2>\n",
    "                <div>\n",
    "                    <p class = \"texte-h2\"> \"Be ashamed to die until you have won some victory for humanity\"</p>\n",
    "                    <p class = \"salaire\"> \"Il est payé 3 €\"</p>\n",
    "                </div>\n",
    "\n",
    "                <h2> Lelouch Vi Britannia </h2>\n",
    "                <div>\n",
    "                    <p class = \"texte-h2\" > \"Vivre sans rien faire est pareil à une mort lente\" </p>\n",
    "                    <p class = \"texte-h2\"> \"I must spill yet more blood, so the blood already split will not be in vain.\" </p>\n",
    "                    <p class = \"salaire\"> \"Il est payé 0€\"</p>\n",
    "                </div>\n",
    "\n",
    "                    <h2> Nabilla </h2>\n",
    "                <div>\n",
    "                    <p class = \"texte-h2\"> \"Non mais allo quoi\"</p>\n",
    "                    <p class = \"salaire\"> \"Elle est payée 3000 €\"</p>\n",
    "                </div>\n",
    "        </div>\n",
    "        \n",
    "        \n",
    "        \n",
    "        <div class=\"block2\">\n",
    "            <h1> Conclusions </h1>\n",
    "                <h2> Une conclusion pas top</h2>\n",
    "                <div>\n",
    "                    <p class =\"travail\"> Work hard !</p>\n",
    "                    <p class = \"famille\" > Par hard !</p>\n",
    "                    <p class = \"party\" > Party hard !</p>\n",
    "                </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"block2 fin\">\n",
    "            <h2> c'est un faux block 2</h2>\n",
    "        </div>\n",
    "        <p id = \"outlier\" title=\"MrMoche\">Ce paragraphe là n'a rien à faire ici 300 €</p\n",
    "    </body>\n",
    "\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "soup = BeautifulSoup(open('meilleurs_citations.html', encoding= 'utf8'),'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#retourne une liste de toutes les balises \"h1\"\n",
    "h1_brut = soup.find_all('h1')\n",
    "print(h1_brut)\n",
    "\n",
    "#retourne une liste de toutes les valeurs à l'intérieur des balises \"h1\"\n",
    "liste_h1 = [h1.string for h1 in h1_brut]\n",
    "liste_h1\n",
    "# On remarque qu'il y' a des espaces de trop qu'il faut supp\n",
    "liste_h1 = [h1.text.strip() for h1 in h1_brut]\n",
    "print(liste_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pareil avec 'p'\n",
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si l'on veut sortir ceux d'une classe en particulier, il faut procéder de la manière suivante\n",
    "soup.find_all('p', {'class':'travail'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nous pouvons accéder au titre avec .attrs (! Cela ne fonctionne que sur un élément, notez le find au lieu du find_all)\n",
    "\n",
    "soup.find(\"p\",{\"id\":'outlier'}).attrs['title'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select permet de récupérer des élements par rapport à leur \"arborescence\"\n",
    "soup.select('div h2') #il cherche dans toute les divs les h2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('div.block2 h2') #il cherche les h2 dans toute les divs ayant la class block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('div.block2.fin h2') #il cherche les h2 dans toute les divs ayant la class block2 et fin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nous pouvons accéder au titre avec .attrs (! Cela ne fonctionne que sur un élément, notez le select_one au lieu du select)\n",
    "soup.select_one(\"#outlier\").attrs['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer toutes les citations\n",
    "div_brut = soup.find_all('p', {'class':'texte-h2'})\n",
    "div_brut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer un dictionnaire avec les noms des auteurs des citations en clés et les citations en valeurs\n",
    "mon_dict = {}\n",
    "\n",
    "citations = soup.select('div.block1 div')\n",
    "print(citations)\n",
    "auteurs = soup.select('div.block1 h2')\n",
    "print(auteurs)\n",
    "\n",
    "for x,y in zip(citations,auteurs):\n",
    "    mon_dict[y.string] = [i.text for i in x.find_all('p',{'class':'texte-h2'})]\n",
    "mon_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculer la moyenne des salaires (en utilisant regex pour récupérer les salaires, évidemment)\n",
    "# !pip install regex\n",
    "import re\n",
    "\n",
    "salaires_brut = soup.select('div.block1 div')\n",
    "print(salaires_brut)\n",
    "salaires = [i.find_all('p',{'class':'salaire'})[0] for i in salaires_brut]\n",
    "print(salaires)\n",
    "salaires_string = [s.string for s in salaires]\n",
    "salaires = [BeautifulSoup.find_all('\\d+', x) for x in salaires_string]\n",
    "salaires\n",
    "\n",
    "\n",
    "# for i in salaires_brut:\n",
    "#     i.find_all('p',{'class':'salaire'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaires1 = []\n",
    "for i in salaires:\n",
    "    for x in i:\n",
    "        salaires1.append(int(x))\n",
    "print(salaires1)   \n",
    "print(np.mean(salaires1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "# Brief Projet 2 : Enquêter sur les mensonges de Donald Trump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans Google, taper : nytimes trump's lies 2017 06 23 et trouver le lien suivant (pour éviter de s'inscrire/s'abonner et ainsi éviter la page floutée)  \n",
    "url_lies : <https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html>  \n",
    "- **Q : Scarpper l'article de journal, Réccuperer, Construire un df et l'Exporter vers fichier csv :**\n",
    "    - _les dates des mensonges_\n",
    "    - _les mensonges correspondants (à chaque date_)\n",
    "    - _les argumentations de l'auteur qui correspondant à chaque mensonge_\n",
    "    - _l'URL de l'argumentation_\n",
    "\n",
    "Le web scraping devra fournir ce df :\n",
    "\n",
    "date | lie | explanation | url\n",
    "--- | --- | --- | ---\n",
    "Jan. 21, 2017 | I wasn't a fan of Iraq. I didn't want to go in... | He was for an invasion before he was against it. | https://www.buzzfeed.com/andrewkaczynski/in-20...\n",
    "Jan. 21, 2017 | A reporter for Time magazine — and I have been... | Trump was on the cover 11 times and Nixon appe... | http://nation.time.com/2013/11/06/10-things-yo...\n",
    "Jan. 23, 2017 | Between 3 million and 5 million illegal votes ... | There's no evidence of illegal voting. | https://www.nytimes.com/2017/01/23/us/politics...\n",
    "Jan. 25, 2017 | Now, the audience was the biggest ever. But th... | Official aerial photos show Obama's 2009 inaug... | https://www.nytimes.com/2017/01/21/us/politics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html')\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jan. 21 “I wasn't a fan of Iraq. I didn't want to go into Iraq.” (He was for an invasion before he was against it.)\n",
      "Jan. 21 “A reporter for Time magazine — and I have been on their cover 14 or 15 times. I think we have the all-time record in the history of Time magazine.” (Trump was on the cover 11 times and Nixon appeared 55 times.)\n",
      "Jan. 23 “Between 3 million and 5 million illegal votes caused me to lose the popular vote.” (There's no evidence of illegal voting.)\n",
      "Jan. 25 “Now, the audience was the biggest ever. But this crowd was massive. Look how far back it goes. This crowd was massive.” (Official aerial photos show Obama's 2009 inauguration was much more heavily attended.)\n",
      "Jan. 25 “Take a look at the Pew reports (which show voter fraud.)” (The report never mentioned voter fraud.)\n",
      "Jan. 25 “You had millions of people that now aren't insured anymore.” (The real number is less than 1 million, according to the Urban Institute.)\n",
      "Jan. 25 “So, look, when President Obama was there two weeks ago making a speech, very nice speech. Two people were shot and killed during his speech. You can't have that.” (There were no gun homicide victims in Chicago that day.)\n",
      "Jan. 26 “We've taken in tens of thousands of people. We know nothing about them. They can say they vet them. They didn't vet them. They have no papers. How can you vet somebody when you don't know anything about them and you have no papers? How do you vet them? You can't.” (Vetting lasts up to two years.)\n",
      "Jan. 26 “I cut off hundreds of millions of dollars off one particular plane, hundreds of millions of dollars in a short period of time. It wasn't like I spent, like, weeks, hours, less than hours, and many, many hundreds of millions of dollars. And the plane's going to be better.” (Most of the cuts were already planned.)\n",
      "Jan. 28 “The coverage about me in the @nytimes and the @washingtonpost has been so false and angry that the Times actually apologized to its dwindling subscribers and readers.” (It never apologized.)\n",
      "Jan. 29 “The Cuban-Americans, I got 84 percent of that vote.” (There is no support for this.)\n",
      "Jan. 30 “Only 109 people out of 325,000 were detained and held for questioning. Big problems at airports were caused by Delta computer outage.” (At least 746 people were detained and processed, and the Delta outage happened two days later.)\n",
      "Feb. 3 “Professional anarchists, thugs and paid protesters are proving the point of the millions of people who voted to MAKE AMERICA GREAT AGAIN!” (There is no evidence of paid protesters.)\n",
      "Feb. 4 “After being forced to apologize for its bad and inaccurate coverage of me after winning the election, the FAKE NEWS @nytimes is still lost!” (It never apologized.)\n",
      "Feb. 5 “We had 109 people out of hundreds of thousands of travelers and all we did was vet those people very, very carefully.” (About 60,000 people were affected.)\n",
      "Feb. 6 “I have already saved more than $700 million when I got involved in the negotiation on the F-35.” (Much of the price drop was projected before Trump took office.)\n",
      "Feb. 6 “It's gotten to a point where it is not even being reported. And in many cases, the very, very dishonest press doesn't want to report it.” (Terrorism has been reported on, often in detail.)\n",
      "Feb. 6 “The failing @nytimes was forced to apologize to its subscribers for the poor reporting it did on my election win. Now they are worse!” (It didn't apologize.)\n",
      "Feb. 6 “And the previous administration allowed it to happen because we shouldn't have been in Iraq, but we shouldn't have gotten out the way we got out. It created a vacuum, ISIS was formed.” (The group’s origins date to 2004.)\n",
      "Feb. 7 “And yet the murder rate in our country is the highest it’s been in 47 years, right? Did you know that? Forty-seven years.” (It was higher in the 1980s and '90s.)\n",
      "Feb. 7 “I saved more than $600 million. I got involved in negotiation on a fighter jet, the F-35.” (The Defense Department projected this price drop before Trump took office.)\n",
      "Feb. 9 “Chris Cuomo, in his interview with Sen. Blumenthal, never asked him about his long-term lie about his brave ‘service’ in Vietnam. FAKE NEWS!” (It was part of Cuomo's first question.)\n",
      "Feb. 9 “Sen. Richard Blumenthal now misrepresents what Judge Gorsuch told him?” (The Gorsuch comments were later corroborated.)\n",
      "Feb. 10 “I don’t know about it. I haven’t seen it. What report is that?” (Trump knew about Flynn's actions for weeks.)\n",
      "Feb. 12 “Just leaving Florida. Big crowds of enthusiastic supporters lining the road that the FAKE NEWS media refuses to mention. Very dishonest!” (The media did cover it.)\n",
      "Feb. 16 “We got 306 because people came out and voted like they've never seen before so that's the way it goes. I guess it was the biggest Electoral College win since Ronald Reagan.” (George H.W. Bush, Bill Clinton and Barack Obama all won bigger margins in the Electoral College.)\n",
      "Feb. 16 “That’s the other thing that was wrong with the travel ban. You had Delta with a massive problem with their computer system at the airports.” (Delta's problems happened two days later.)\n",
      "Feb. 16 “Walmart announced it will create 10,000 jobs in the United States just this year because of our various plans and initiatives.” (The jobs are a result of its investment plans announced in Oct. 2016.)\n",
      "Feb. 16 “When WikiLeaks, which I had nothing to do with, comes out and happens to give, they’re not giving classified information.” (Not always. They have released classified information in the past.)\n",
      "Feb. 16 “We had a very smooth rollout of the travel ban. But we had a bad court. Got a bad decision.” (The rollout was chaotic.)\n",
      "Feb. 16 “They’re giving stuff — what was said at an office about Hillary cheating on the debates. Which, by the way, nobody mentions. Nobody mentions that Hillary received the questions to the debates.” (It was widely covered.)\n",
      "Feb. 18 “And there was no way to vet those people. There was no documentation. There was no nothing.” (Refugees receive multiple background checks, taking up to two years.)\n",
      "Feb. 18 “You look at what's happening in Germany, you look at what's happening last night in Sweden. Sweden, who would believe this?” (Trump implied there was a terror attack in Sweden, but there was no such attack.)\n",
      "Feb. 24 “By the way, you folks are in here — this place is packed, there are lines that go back six blocks.” (There was no evidence of long lines.)\n",
      "Feb. 24 “ICE came and endorsed me.” (Only its union did.)\n",
      "Feb. 24 “Obamacare covers very few people — and remember, deduct from the number all of the people that had great health care that they loved that was taken away from them — it was taken away from them.” (Obamacare increased coverage by a net of about 20 million.)\n",
      "Feb. 27 “Since Obamacare went into effect, nearly half of the insurers are stopped and have stopped from participating in the Obamacare exchanges.” (Many fewer pulled out.)\n",
      "Feb. 27 “On one plane, on a small order of one plane, I saved $725 million. And I would say I devoted about, if I added it up, all those calls, probably about an hour. So I think that might be my highest and best use.” (Much of the price cut was already projected.)\n",
      "Feb. 28 “And now, based on our very strong and frank discussions, they are beginning to do just that.” (NATO countries agreed to meet defense spending requirements in 2014.)\n",
      "Feb. 28 “The E.P.A.’s regulators were putting people out of jobs by the hundreds of thousands.” (There's no evidence that the Waters of the United States rule caused severe job losses.)\n",
      "Feb. 28 “We have begun to drain the swamp of government corruption by imposing a five-year ban on lobbying by executive branch officials.” (They can't lobby their former agency but can still become lobbyists.)\n",
      "March 3 “It is so pathetic that the Dems have still not approved my full Cabinet.” (Paperwork for the last two candidates was still not submitted to the Senate.)\n",
      "March 4 “Terrible! Just found out that Obama had my ‘wires tapped’ in Trump Tower just before the victory. Nothing found. This is McCarthyism!” (There's no evidence of a wiretap.)\n",
      "March 4 “How low has President Obama gone to tap my phones during the very sacred election process. This is Nixon/Watergate. Bad (or sick) guy!” (There's no evidence of a wiretap.)\n",
      "March 7 “122 vicious prisoners, released by the Obama Administration from Gitmo, have returned to the battlefield. Just another terrible decision!” (113 of them were released by President George W. Bush.)\n",
      "March 13 “I saved a lot of money on those jets, didn't I? Did I do a good job? More than $725 million on them.” (Much of the cost cuts were planned before Trump.)\n",
      "March 13 “First of all, it covers very few people.” (About 20 million people gained insurance under Obamacare.)\n",
      "March 15 “On the airplanes, I saved $725 million. Probably took me a half an hour if you added up all of the times.” (Much of the cost cuts were planned before Trump.)\n",
      "March 17 “I was in Tennessee — I was just telling the folks — and half of the state has no insurance company, and the other half is going to lose the insurance company.” (There's at least one insurer in every Tennessee county.)\n",
      "March 20 “With just one negotiation on one set of airplanes, I saved the taxpayers of our country over $700 million.” (Much of the cost cuts were planned before Trump.)\n",
      "March 21 “To save taxpayer dollars, I’ve already begun negotiating better contracts for the federal government — saving over $700 million on just one set of airplanes of which there are many sets.” (Much of the cost cuts were planned before Trump.)\n",
      "March 22 “I make the statement, everyone goes crazy. The next day they have a massive riot, and death, and problems.” (Riots in Sweden broke out two days later and there were no deaths.)\n",
      "March 22 “NATO, obsolete, because it doesn’t cover terrorism. They fixed that.” (It has fought terrorism since the 1980s.)\n",
      "March 22 “Well, now, if you take a look at the votes, when I say that, I mean mostly they register wrong — in other words, for the votes, they register incorrectly and/or illegally. And they then vote. You have tremendous numbers of people.” (There's no evidence of widespread voter fraud.)\n",
      "March 29 “Remember when the failing @nytimes apologized to its subscribers, right after the election, because their coverage was so wrong. Now worse!” (It didn't apologize.)\n",
      "March 31 “We have a lot of plants going up now in Michigan that were never going to be there if I — if I didn’t win this election, those plants would never even think about going back. They were gone.” (These investments were already planned.)\n",
      "April 2 “And I was totally opposed to the war in the Middle East which I think finally has been proven, people tried very hard to say I wasn’t but you’ve seen that it is now improving.” (He was for an invasion before he was against it.)\n",
      "April 2 “Now, my last tweet — you know, the one that you are talking about, perhaps — was the one about being, in quotes, wiretapped, meaning surveilled. Guess what, it is turning out to be true.” (There is still no evidence.)\n",
      "April 5 “You have many states coming up where they’re going to have no insurance company. O.K.? It’s already happened in Tennessee. It’s happening in Kentucky. Tennessee only has half coverage. Half the state is gone. They left.” (Every marketplace region in Tennessee had at least one insurer.)\n",
      "April 6 “If you look at the kind of cost-cutting we’ve been able to achieve with the military and at the same time ordering vast amounts of equipment — saved hundreds of millions of dollars on airplanes, and really billions, because if you take that out over a period of years it’s many billions of dollars — I think we’ve had a tremendous success.” (Much of the price cuts were already projected.)\n",
      "April 11 “I like Steve, but you have to remember he was not involved in my campaign until very late. I had already beaten all the senators and all the governors, and I didn’t know Steve.” (He knew Steve Bannon since 2011.)\n",
      "April 12 “You can't do it faster, because they're obstructing. They're obstructionists. So I have people — hundreds of people that we're trying to get through. I mean you have — you see the backlog. We can't get them through.” (At this point, he had not nominated anyone for hundreds of positions.)\n",
      "April 12 “The New York Times said the word wiretapped in the headline of the first edition. Then they took it out of there fast when they realized.” (There were separate headlines for print and web, but neither were altered.)\n",
      "April 12 “The secretary general and I had a productive discussion about what more NATO can do in the fight against terrorism. I complained about that a long time ago and they made a change, and now they do fight terrorism.” (NATO has been engaged in counterterrorism efforts since the 1980s.)\n",
      "April 12 “Mosul was supposed to last for a week and now they’ve been fighting it for many months and so many more people died.” (The campaign was expected to take months.)\n",
      "April 16 “Someone should look into who paid for the small organized rallies yesterday. The election is over!” (There's no evidence of paid protesters.)\n",
      "April 18 “The fake media goes, ‘Donald Trump changed his stance on China.’ I haven’t changed my stance.” (He did.)\n",
      "April 21 “On 90 planes I saved $725 million. It's actually a little bit more than that, but it's $725 million.” (Much of the price cuts were already projected.)\n",
      "April 21 “When WikiLeaks came out ... never heard of WikiLeaks, never heard of it.” (He criticized it as early as 2010.)\n",
      "April 27 “I want to help our miners while the Democrats are blocking their healthcare.” (The bill to extend health benefits for certain coal miners was introduced by a Democrat and was co-sponsored by mostly Democrats.)\n",
      "April 28 “The trade deficit with Mexico is close to $70 billion, even with Canada it’s $17 billion trade deficit with Canada.” (The U.S. had an $8.1 billion trade surplus, not deficit, with Canada in 2016.)\n",
      "April 28 “She's running against someone who's going to raise your taxes to the sky, destroy your health care, and he's for open borders — lots of crime.” (Those are not Jon Ossoff's positions.)\n",
      "April 28 “The F-35 fighter jet program — it was way over budget. I’ve saved $725 million plus, just by getting involved in the negotiation.” (Much of the price cuts were planned before Trump.)\n",
      "April 29 “As you know, I've been a big critic of China, and I've been talking about currency manipulation for a long time. But I have to tell you that during the election, number one, they stopped.” (China stopped years ago.)\n",
      "April 29 “I've already saved more than $725 million on a simple order of F-35 planes. I got involved in the negotiation.” (Much of the price cuts were planned before Trump.)\n",
      "April 29 “We're also getting NATO countries to finally step up and contribute their fair share. They've begun to increase their contributions by billions of dollars, but we are not going to be satisfied until everyone pays what they owe.” (The deal was struck in 2014.)\n",
      "April 29 “When they talk about currency manipulation, and I did say I would call China, if they were, a currency manipulator, early in my tenure. And then I get there. Number one, they — as soon as I got elected, they stopped.” (China stopped in 2014.)\n",
      "April 29 “I was negotiating to reduce the price of the big fighter jet contract, the F-35, which was totally out of control. I will save billions and billions and billions of dollars.” (Most of the cuts were planned before Trump.)\n",
      "April 29 “I think our side's been proven very strongly. And everybody's talking about it.” (There's still no evidence Trump's phones were tapped.)\n",
      "May 1 “Well, we are protecting pre-existing conditions. And it'll be every good — bit as good on pre-existing conditions as Obamacare.” (The bill weakens protections for people with pre-existing conditions.)\n",
      "May 1 “The F-35 fighter jet — I saved — I got involved in the negotiation. It's 2,500 jets. I negotiated for 90 planes, lot 10. I got $725 million off the price.” (Much of the price cuts were planned before Trump.)\n",
      "May 1 “First of all, since I started running, they haven't increased their — you know, they have not manipulated their currency. I think that was out of respect to me and the campaign.” (China stopped years ago.)\n",
      "May 2 “I love buying those planes at a reduced price. I have been really — I have cut billions — I have to tell you this, and they can check, right, Martha? I have cut billions and billions of dollars off plane contracts sitting here.” (Much of the cost cuts were planned before Trump.)\n",
      "May 4 “Number two, they’re actually not a currency [manipulator]. You know, since I’ve been talking about currency manipulation with respect to them and other countries, they stopped.” (China stopped years ago.)\n",
      "May 4 “We’re the highest-taxed nation in the world.” (We're not.)\n",
      "May 4 “Nobody cares about my tax return except for the reporters.” (Polls show most Americans do care.)\n",
      "May 8 “You know we’ve gotten billions of dollars more in NATO than we’re getting. All because of me.” (The deal was struck in 2014.)\n",
      "May 8 “But when I did his show, which by the way was very highly rated. It was high — highest rating. The highest rating he’s ever had.” (Colbert's Late Show debut had nearly two million more viewers.)\n",
      "May 8 “Director Clapper reiterated what everybody, including the fake media already knows — there is ‘no evidence’ of collusion w/ Russia and Trump.” (Clapper only said he wasn't aware of an investigation.)\n",
      "May 12 “Again, the story that there was collusion between the Russians & Trump campaign was fabricated by Dems as an excuse for losing the election.” (The F.B.I. was investigating before the election.)\n",
      "May 12 “When James Clapper himself, and virtually everyone else with knowledge of the witch hunt, says there is no collusion, when does it end?” (Clapper said he wouldn't have been told of an investigation into collusion.)\n",
      "May 13 “I'm cutting the price of airplanes with Lockheed.” (The cost cuts were planned before he became president.)\n",
      "May 26 “Just arrived in Italy for the G7. Trip has been very successful. We made and saved the USA many billions of dollars and millions of jobs.” (He's referencing an arms deal that's not enacted and other apparent deals that weren't announced on the trip.)\n",
      "June 1 “China will be allowed to build hundreds of additional coal plants. So, we can’t build the plants, but they can, according to this agreement. India will be allowed to double its coal production by 2020.” (The agreement doesn’t allow or disallow building coal plants.)\n",
      "June 1 “I’ve just returned from a trip overseas where we concluded nearly $350 billion of military and economic development for the United States, creating hundreds of thousands of jobs.” (Trump’s figures are inflated and premature.)\n",
      "June 4 “At least 7 dead and 48 wounded in terror attack and Mayor of London says there is ‘no reason to be alarmed!’” (The mayor was specifically talking about the enlarged police presence on the streets.)\n",
      "June 5 “The Justice Dept. should have stayed with the original Travel Ban, not the watered down, politically correct version they submitted to S.C.” (Trump signed this version of the travel ban, not the Justice Department.)\n",
      "June 20 “Well, the Special Elections are over and those that want to MAKE AMERICA GREAT AGAIN are 5 and O!” (Republicans have won four special elections this year, while a Democrat won one.)\n",
      "June 21 “They all say it's 'nonbinding.' Like hell it's nonbinding.” (The Paris climate agreement is nonbinding — and Trump said so in his speech announcing the withdrawal.)\n",
      "June 21 “Right now, we are one of the highest-taxed nations in the world.” (We're not.)\n",
      "June 21 “You have a gang called MS-13. ... We are moving them out of the country by the thousands, by the thousands.” (The real number of gang members deported is smaller.)\n",
      "June 21 “Your insurance companies have all fled the state of Iowa.” (They haven't.)\n",
      "June 21 “If [farmers] have a puddle in the middle of their field ... it's considered a lake and you can't touch it. ... We got rid of that one, too, O.K.?” (The Obama environmental rule to limit pollution in the country’s waters explicitly excludes puddles.)\n",
      "June 21 “Gary Cohn just paid $200 million in tax in order to take this job, by the way.” (Cohn sold Goldman Sachs stock worth $220 million.)\n",
      "June 21 “We’re 5 and 0.” (Republicans have won four special elections this year, while a Democrat won one.)\n",
      "June 21 “Last week a brand-new coal mine just opened in the state of Pennsylvania, first time in decades, decades.” (Another coal mine opened in 2014.)\n",
      "June 22 “Former Homeland Security Advisor Jeh Johnson is latest top intelligence official to state there was no grand scheme between Trump & Russia.” (Johnson, who had a different title, didn't say that.)\n",
      "June 23 “We are 5 and 0 ... in these special elections.” (Republicans have won four special elections this year, while a Democrat won one.)\n",
      "June 27 “Ratings way down!” (CNN's ratings were at a five-year high at the time.)\n",
      "June 28 “Democrats purposely misstated Medicaid under new Senate bill — actually goes up.” (Senate bill would have cut the program deeply.)\n",
      "June 29 “General Kelly and his whole group — they’ve gotten rid of 6,000 so far.” (The real number of MS-13 gang members who have been deported is smaller.)\n",
      "July 6 “As a result of this insistence, billions of dollars more have begun to pour into NATO.” (NATO countries agreed to meet defense spending requirements in 2014.)\n",
      "July 17 “We’ve signed more bills — and I’m talking about through the legislature — than any president, ever.” (Clinton, Carter, Truman, and F.D.R. had signed more at the same point.)\n",
      "July 19 “Um, the Russian investigation — it’s not an investigation, it’s not on me — you know, they’re looking at a lot of things.” (It is.)\n",
      "July 19 “I heard that Harry Truman was first, and then we beat him. These are approved by Congress. These are not just executive orders.” (Presidents Clinton, Carter, Truman, and F.D.R. each had signed more legislation than Trump at the same point in their terms.)\n",
      "July 19 “But the F.B.I. person really reports directly to the president of the United States, which is interesting.” (He reports directly to the attorney general.)\n",
      "July 19 “She did the uranium deal, which is a horrible thing, while she was secretary of state, and got a lot of money.” (There's no evidence Hillary Clinton was actively involved or benefited from the deal.)\n",
      "July 24 “It looks like about 45,000 people. You set a record today.” (Many fewer than 45,000 were there, and the attendance was not a record.)\n",
      "July 25 “We have the highest taxes anywhere in the world, and this will really bring them down to one of the lowest.” (Tax rates in the United States are below average, overall and for an industrialized country.)\n",
      "July 25 “We’re the highest-taxed nation in the world” (We're not.)\n",
      "July 25 “We have nearly doubled the number of veterans given approvals to see the doctor of their choice.” (The increase was 26 percent.)\n",
      "July 25 “Since I took office we have cut illegal immigration on our southern border by record numbers. 78 percent.” (The decline began before Trump's inauguration.)\n",
      "July 28 “The previous administration enacted an open-door policy to illegal migrants from Central America.  \"Welcome in. Come in, please, please.” (Obama deported millions.)\n",
      "July 28 “We have trade deficits with almost every country because we had a lot of really bad negotiators making deals with other countries.” (The U.S. has a trade surplus with more than 100 countries.)\n",
      "July 31 “2.6 is a number that nobody thought they’d see for a long period of time.” (Many experts predicted economic growth at least this high.)\n",
      "July 31 “And even the President of Mexico called me  – they said their southern border, very few people are coming because they know they’re not going to get through our border, which is the ultimate compliment.” (Mexico's president says he didn't call Trump.)\n",
      "Aug. 1 “And I think to me, maybe the biggest is that GDP for the quarter just released at 2.6 percent. So that's so much higher than anticipated.” (It wasn't.)\n",
      "Aug. 3 “Economic growth has surged to 2.6% nationwide. You have to understand what that means. Nobody thought that number was going to happen.” (Many experts predicted that.)\n",
      "Aug. 3 “The Russia story is a total fabrication.” (It's not.)\n",
      "Aug. 3 “Or let them look at the uranium she sold that is now in the hands of very angry Russians.” (There's no evidence Hillary Clinton was actively involved in the sale.)\n",
      "Aug. 15 “We want products made in the country. Now, I have to tell you, some of the folks that will leave, they're leaving out of embarrassment because they make their products outside.” (People resigned from Trump's business councils over his Charlottesville comments.)\n",
      "Aug. 22 “Remember, everybody said you won’t bring it up to 1 percent. You won’t bring it up to 1.2 percent.” (Many experts predicted economic growth at least this high.)\n",
      "Aug. 22 “I mean truly dishonest people in the media and the fake media, they make up stories. They have no sources in many cases. They say 'a source says'  – there is no such thing.” (The media does not make up sources.)\n",
      "Aug. 22 “As everybody here remembers, this was the scene of my first rally speech, right?” (Trump's first rally was in New Hampshire)\n",
      "Aug. 22 “We have become an energy exporter for the first time ever just recently.” (The U.S. isn't projected to become a net energy exporter until 2026.)\n",
      "Aug. 22 “Look back there, the live red lights. They're turning those suckers off fast out there. They're turning those lights off fast. Like CNN.” (CNN didn't turn off its cameras.)\n",
      "Sept. 6 “The taxes are crazy  – the highest-taxed nation in the world.” (We're not.)\n",
      "Sept. 6 “We are the highest taxed nation in the world - that will change.” (We're not.)\n",
      "Sept. 8 “Our incredible U.S. Coast Guard saved more than 15,000 lives last week with Harvey.” (The real number is 11,022.)\n",
      "Sept. 14 “Also with the fact that I know in the case of FEMA and the case of Coast Guard, the job you've done in saving people, saving lives.  As an example, in Harvey in Texas, we talked  – over 16,000 lives.” (The real number is smaller.)\n",
      "Sept. 14 “And in Florida you got hit with the strongest winds ever recorded.” (They weren't the strongest ever recorded.)\n",
      "Sept. 22 “We've been dealing with ICE, we've been dealing with the Border Patrol. They both endorsed me.” (Neither agency endorsed him; only their unions did.)\n",
      "Sept. 22 “So he started off here, he was in third or fourth, he went to third, second, and now it's like almost pretty even.” (Strange consistently polled first or second in the Alabama Republican primary.)\n",
      "Sept. 29 “With the F-35 fighter plane  – me, myself  – I've saved hundreds of millions of dollars in negotiating.” (The cost cuts were planned before he became president.)\n",
      "Sept. 27 “I’m doing the right thing, and it’s not good for me.” (All available evidence suggests he would benefit.)\n",
      "Sept. 27 “To protect millions of small businesses and the American farmer, we are finally ending the crushing, the horrible, the unfair estate tax.” (The real number of small businesses and farmers is vastly smaller.)\n",
      "Sept. 27 “No, I don't benefit. I don't benefit. In fact, very very strongly, as you see, I think there's very little benefit for people of wealth.” (The tax plan would personally benefit Trump and other wealthy individuals.)\n",
      "Sept. 27 “Facebook was always anti-Trump.The Networks were always anti-Trump hence,Fake News, @nytimes(apologized) & @WaPo were anti-Trump.” (The Times did not apologize for its Trump coverage.)\n",
      "Sept. 28 “I mean right now, we're the highest-taxed nation in the world.” (We're not.)\n",
      "Oct. 3 “But the Coast Guard itself saved in Texas 16,000 lives, and they went right through that hurricane.” (The real number is smaller.)\n",
      "Oct. 3 “But that's an expensive plane that you can't see. And as you probably heard, we cut the price very substantially  – something that other administrations would never have done, that I can tell you.” (The cost cuts were planned before he became president.)\n",
      "Oct. 6 “I was able to reduce the price of the Lockheed by billions of dollars.” (The cost cuts were planned before he became president.)\n",
      "Oct. 6 “We're the highest-taxed developed nation in the world, probably the highest-taxed nation in the world.” (We're not.)\n",
      "Oct. 6 “They also just said that there has been absolutely no collusion. They just said that. Yesterday. Two days ago. Senate. There has been no collusion.” (The Senate didn't say that.)\n",
      "Oct. 6 “This tax cut and tax reform is going very well, and it's going to be a tremendous boost for our country, including the fact that we're the highest-taxed nation in the world.” (We're not.)\n",
      "Oct. 7 “We're the highest-taxed nation in the world.” (We're not.)\n",
      "Oct. 7 “The Coast Guard, in Texas, and all over, but with the job they did in Texas, I saw, they saved 16,000 lives.” (The real number is smaller.)\n",
      "Oct. 7 “Obama should have never gotten out the way he got out. That's how ISIS formed.” (The group’s origins date to 2004.)\n",
      "Oct. 10 “The Failing @nytimes set Liddle' Bob Corker up by recording his conversation. Was made to sound a fool, and that's what I am dealing with!” (Corker asked the Times reporter to record the call; his aides recorded it too.)\n",
      "Oct. 10 “We're the highest-taxed nation in the world.” (We're not.)\n",
      "Oct. 11 “We have missiles that can knock out a missile in the air. Ninety seven per cent of the time. If you send two of them, it's going to get knocked out.” (The effectiveness rate is about 60 percent.)\n",
      "Oct. 16 “We're the highest-taxed country in the world.” (We're not.)\n",
      "Oct. 16 “I hear that Ireland is going to be reducing their corporate rates down to 8 percent from 12.” (Ireland has no plans to cut its tax rate.)\n",
      "Oct. 16 “If you look at President Obama and other presidents, most of them didn’t make calls.” (They did call families of soldiers killed in action.)\n",
      "Oct. 16 “All I can say is it's totally fake news, just fake. It's fake. It's made-up stuff, and it's disgraceful what happens, but that happens in the world of politics.” (Trump himself has bragged about groping women.)\n",
      "Oct. 17 “We're the highest taxed nation in the world.” (We're not.)\n",
      "Oct. 17 “Right now, we are the highest-taxed nation anywhere in the world. You can even say developed or undeveloped.” (We're not.)\n",
      "Oct. 17 “As far as I'm concerned, I think we're really essentially the highest. But if you'd like to add the developed nation, you can say that, too.” (Taxes in the U.S. are lower than in most developed countries.)\n",
      "Oct. 17 “We're the highest-taxed nation in the world. We are taxed beyond belief.” (We're not.)\n",
      "Oct. 17 “Well, we're the highest-taxed nation in the world.” (We're not.)\n",
      "Oct. 17 “I wish President Obama didn't get out the way he got out. Because that left a vacuum and ISIS was formed.” (The group’s origins date to 2004.)\n",
      "Oct. 18 “Democrat Congresswoman totally fabricated what I said to the wife of a soldier who died in action (and I have proof).” (The wife confirmed Representative Frederica Wilson's account.)\n",
      "Oct. 18 “The Coast Guard in Texas saved 16,000 lives.” (The real number was smaller.)\n",
      "Oct. 18 “Nobody has ever heard of a five hitting land.” (Category 5 storms have hit land before.)\n",
      "Oct. 24 “Under our plan, more than 30 million Americans who own small businesses will get a 40 per cent cut to their top marginal tax rate.” (The real number is estimated to be less than 1 million.)\n",
      "Oct. 25 “We have trade deficits with almost everybody.” (We have trade surpluses with more than 100 countries.)\n",
      "Oct. 27 “Wacky & totally unhinged Tom Steyer, who has been fighting me and my Make America Great Again agenda from beginning, never wins elections!” (Steyer has financially supported many winning candidates.)\n",
      "Nov. 1 “Again, we're the highest-taxed nation, just about, in the world.” (We're not.)\n",
      "Nov. 7 “When you look at the city with the strongest gun laws in our nation, it's Chicago.” (Several other cities, including New York and Los Angeles, have stronger gun laws.)\n",
      "Nov. 11 “I'd rather have him  – you know, work with him on the Ukraine than standing and arguing about whether or not  – because that whole thing was set up by the Democrats.” (There is no evidence that Democrats \"set up\" Russian interference in the election.)\n"
     ]
    }
   ],
   "source": [
    "# mon cas de test locall\n",
    "import re\n",
    "url3 = 'https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html'\n",
    "trump = requests.get(url3)\n",
    "trumpSoup = BeautifulSoup(trump.content)\n",
    "date = trumpSoup.findAll('strong')\n",
    "\n",
    "#for d in date :\n",
    " #   if(d != 'Updated'):\n",
    "  #      print(d.get_text())\n",
    "\n",
    "#dates\n",
    "#evens = trumpSoup.findAll(True,{'class':['short-desc', 'strong']})\n",
    "#evenshort =    trumpSoup.findAll(True,{'class':['short-truth', 'strong']})\n",
    "\n",
    "#for text in evenshorttruth:\n",
    " #   print(text.get_text())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T10:46:31.872907Z",
     "end_time": "2023-04-18T10:46:32.039901Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    #evenDateshorttruth : faux propos\n",
    "for strong_tag in trumpSoup.find_all(True,{'class':['short-truth', 'strong']}):\n",
    "    print(strong_tag.text, strong_tag.next_sibling)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#evenDateshort: vrais propos\n",
    "for strong_tag in trumpSoup.find_all(True,{'class':['short-desc', 'strong']}):\n",
    "    print(strong_tag.text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T17:13:26.820252Z",
     "end_time": "2023-04-17T17:13:26.828164Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html')\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(r.content, 'html.parser')\n",
    "# soup.prettify()\n",
    "# results = soup.find_all('span', attrs={'class':'short-desc'})\n",
    "# print(len(results))\n",
    "pprint(results[0:3])\n",
    "# results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire la date\n",
    "# first_result = results[0]\n",
    "print(first_result)\n",
    "print(first_result.find('strong'))\n",
    "print(first_result.find('strong').text.strip())\n",
    "print(first_result.find('strong').text[0:-1] + ', 2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire le mensonge\n",
    "print(first_result) \n",
    "print()\n",
    "print(first_result.contents) \n",
    "print()\n",
    "print(first_result.contents[1]) \n",
    "print()\n",
    "print(first_result.contents[1][1:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire l'explication\n",
    "print(first_result.contents[2])\n",
    "print()\n",
    "print(first_result.find('a'))\n",
    "print()\n",
    "print(first_result.find('a').text[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the URL\n",
    "print(first_result.find('a'))\n",
    "print()\n",
    "print(first_result.find('a')['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the dataset \n",
    "records = []\n",
    "for result in results:\n",
    "    date = result.find('strong').text[0:-1] + ', 2017'\n",
    "    lie = result.contents[1][1:-2]\n",
    "    explanation = result.find('a').text[1:-1]\n",
    "    url = result.find('a')['href']\n",
    "    records.append((date, lie, explanation, url))\n",
    "print(len(records))  \n",
    "pprint(records[0 : 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(records, columns=['date', 'lie', 'explanation', 'url'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"rump_lies.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da03a2949bd7f7e1e2f8a272eaea5cb5c8effd8622bbe3cc4e7f8a7d557202f6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
